# Scraper QA Report

**Date:** February 12, 2026  
**Tester:** GitHub Copilot  
**Environment:** Local (Linux), Poetry virtualenv, Playwright installed  
**Objective:** Determine why each scraper fails to return real data and identify mock/fake data fallback paths

---

## Summary

| # | Scraper | File | Real Data? | Root Cause |
|---|---------|------|:----------:|------------|
| 1 | PFF Playwright | `data_pipeline/scrapers/pff_scraper_playwright.py` | âŒ | Wrong CSS selectors + silent fallback to hardcoded mock data |
| 2 | PFF Production | `data_pipeline/scrapers/pff_scraper.py` | âŒ | Wrong CSS selectors (`div.card-prospects-box` doesn't exist) |
| 3 | PFF PoC (requests) | `data_pipeline/scrapers/pff_scraper_poc.py` | âŒ | Uses `requests` only â€” page is JS-rendered, gets empty HTML |
| 4 | PFF Selenium | `data_pipeline/scrapers/pff_scraper_selenium.py` | âŒ | Wrong CSS selectors; generic h3/h4 parsing is fragile |
| 5 | ESPN Injury | `data_pipeline/sources/espn_injury_scraper.py` | âŒ | Wrong URL (trailing slash) + wrong CSS selectors |
| 6 | Yahoo Sports | `data_pipeline/sources/yahoo_sports_scraper.py` | âŒ | Wrong CSS selectors + hardcoded mock fallback in production path |
| 7 | NFL Draft Connector | `data_pipeline/sources/nfl_draft_connector.py` | âŒ | Wrong ESPN API URL (403) + hardcoded `MOCK_PROSPECTS` fallback |

**Verdict: 0 of 7 scrapers return real data. 3 of 7 silently return fake/mock data in their production code paths.**

---

## Detailed Findings

---

### 1. PFF Playwright Scraper â€” `data_pipeline/scrapers/pff_scraper_playwright.py`

**Test Command:**
```bash
poetry run python -c "
from data_pipeline.scrapers.pff_scraper_playwright import PFFScraperPlaywright
import asyncio
scraper = PFFScraperPlaywright(season=2026, headless=True)
prospects = asyncio.run(scraper.scrape_all_pages(max_pages=1))
print(f'{len(prospects)} prospects')
"
```

**Result:** Returns 3 prospects â€” **all hardcoded fake data** (Patrick Surtain III, Will Anderson Jr, Jalen Carter â€” names from the 2023 draft).

**Root Causes:**

1. **Wrong CSS selector:** Searches for `div.card-prospects-box` â€” this class does not exist on PFF.com. The actual prospect card container is `div.g-card.g-card--border-gray`.

2. **Silent mock data fallback (line 112â€“150):** When Playwright throws *any* exception (including `TimeoutError`), the `except` block calls `_demo_with_mock_data()` which injects 3 hardcoded fake prospects and returns them as if they were real. The error message actively misleads: *"This is an environment limitation, not a code issue."*

3. **Wrong field selectors:** Searches for `<span class="school">`, `<span class="position">`, etc. The actual PFF structure uses `<div class="g-label">` / `<div class="g-data">` pairs inside `<div class="m-stat">` containers.

**Actual PFF DOM structure (from live page capture):**
```
div.g-card.g-card--border-gray
â”œâ”€â”€ div.m-ranking-header
â”‚   â”œâ”€â”€ div.m-rank â†’ div.m-rank__value (rank number)
â”‚   â”œâ”€â”€ div.m-ranking-header__title â†’ a (player name)
â”‚   â””â”€â”€ div.m-ranking-header__details
â”‚       â””â”€â”€ div.m-stat (Ã—2: Position, Class)
â”‚           â”œâ”€â”€ div.g-label ("Position" / "Class")
â”‚           â””â”€â”€ div.g-data ("QB" / "RS Jr.")
â””â”€â”€ div.g-card__content
    â”œâ”€â”€ div.m-stat-cluster (School, Age, Height, Weight, Speed)
    â”‚   â””â”€â”€ div (Ã—5)
    â”‚       â”œâ”€â”€ div.g-label
    â”‚       â””â”€â”€ div.g-data
    â””â”€â”€ table.g-table (Season, Snaps, Season Grade)
```

**Mock Data That Should Be Removed:**
- Lines 118â€“150: `_demo_with_mock_data()` method with hardcoded HTML containing fake prospects

---

### 2. PFF Production Scraper â€” `data_pipeline/scrapers/pff_scraper.py`

**Test Command:**
```bash
poetry run python -c "
from data_pipeline.scrapers.pff_scraper import PFFScraper
import asyncio
scraper = PFFScraper(season=2026, headless=True, cache_enabled=False)
prospects = asyncio.run(scraper.scrape_all_pages(max_pages=1))
print(f'{len(prospects)} prospects')
"
```

**Result:** Returns 0 prospects. Playwright successfully loads the page (1.4 MB HTML) but finds nothing.

**Root Causes:**

1. **Wrong CSS selector:** Uses `div.card-prospects-box` which doesn't exist. The actual container is `div.g-card`.

2. **Wrong field selectors:** `parse_prospect()` searches for `<h3>/<h4>` tags and `<span class="school/position/grade">` â€” none of these exist in PFF's actual HTML.

3. **Caches empty results:** After finding 0 prospects, the scraper *caches* the empty result to `data/cache/pff/season_2026_page_1.json`. On subsequent runs with caching enabled, it returns 0 prospects instantly from cache without ever retrying the real page.

4. **Debug HTML dump left in:** Line ~285 writes `page_1.html` to the working directory on every run â€” a debug artifact that shouldn't be in production.

**Verified from cache file:**
```json
{"timestamp": 1770850470.7, "season": 2026, "page": 1, "prospects": [], "count": 0}
```

---

### 3. PFF PoC Scraper (requests only) â€” `data_pipeline/scrapers/pff_scraper_poc.py`

**Result:** Returns 0 prospects.

**Root Cause:** Uses `requests.get()` with BeautifulSoup only. PFF's big board is **fully JavaScript-rendered** â€” the server returns a shell HTML page and all prospect data is loaded client-side via JS. This is acknowledged in the file's own docstring (*"Page IS JavaScript-rendered (NOT server-rendered)"*) but the code was never updated to handle this.

**Additional issue:** Even if the page were server-rendered, the CSS selectors (`div` with `string=re.compile(r"PFF Rank")` and sibling parsing) don't match PFF's actual DOM structure.

**Status:** This file is correctly marked as a PoC, but it should probably be removed or archived since it's confirmed non-functional and the Playwright version supersedes it.

---

### 4. PFF Selenium Scraper â€” `data_pipeline/scrapers/pff_scraper_selenium.py`

**Result:** Not tested (Selenium/ChromeDriver not installed), but code analysis shows it would fail.

**Root Causes:**

1. **Generic selector:** Uses `EC.presence_of_all_elements_located((By.CSS_SELECTOR, "h3, h4"))` â€” this matches *any* h3/h4 on the page (nav links, headers, etc.), not just prospect names.

2. **Fragile parsing:** `parse_prospect()` walks parent elements looking for text lines starting with "POSITION", "CLASS", "SCHOOL", etc. PFF uses `<div class="g-label">Position</div>` / `<div class="g-data">QB</div>` pattern, so text-line parsing won't extract clean fields.

3. **Superseded:** The file header itself recommends switching to Playwright. This scraper is obsolete.

---

### 5. ESPN Injury Scraper â€” `data_pipeline/sources/espn_injury_scraper.py`

**Test Command:**
```bash
poetry run python -c "
from data_pipeline.sources.espn_injury_scraper import ESPNInjuryConnector
c = ESPNInjuryConnector()
injuries = c.fetch_injuries()
print(f'{len(injuries)} injuries')
"
```

**Result:** Returns 0 injuries. HTTP 404 error.

**Root Causes:**

1. **Wrong URL:** `BASE_URL = "https://www.espn.com/nfl/injuries/"` â€” the trailing slash causes a 404. The correct URL is `https://www.espn.com/nfl/injuries` (no trailing slash). Verified:
   - `https://www.espn.com/nfl/injuries` â†’ 200 OK (870 KB)
   - `https://www.espn.com/nfl/injuries/` â†’ 404

2. **Wrong CSS selectors:** The scraper looks for `tr.injury-row`, `td.player-name`, `td.player-position`, `td.injury-type`, `td.injury-status`, `td.return-date`. None of these exist. ESPN's actual structure uses:
   - `tr.Table__TR` â€” row class
   - `td.col-name` â€” player name
   - `td.col-pos` â€” position
   - `td.col-date` â€” return date
   - `td.col-stat` â†’ `span.TextStatus` â€” injury status
   - `td.col-desc` â€” comment

3. **No team extraction:** ESPN groups injuries by team using a header above each table, not within each row. The scraper expects a `td.player-team` column that doesn't exist.

**ESPN actual row example:**
```html
<tr class="Table__TR Table__TR--sm Table__even">
  <td class="col-name Table__TD"><a href="...">Jonah Williams</a></td>
  <td class="col-pos Table__TD">OT</td>
  <td class="col-date Table__TD">Mar 1</td>
  <td class="col-stat Table__TD"><span class="TextStatus TextStatus--yellow">Questionable</span></td>
  <td class="col-desc Table__TD"></td>
</tr>
```

**Note:** ESPN has 32 tables (one per team) with 569 total injury rows of real data available right now, so this is very fixable.

---

### 6. Yahoo Sports Scraper â€” `data_pipeline/sources/yahoo_sports_scraper.py`

**Test Command:**
```bash
poetry run python -c "
from data_pipeline.sources.yahoo_sports_scraper import YahooSportsConnector
c = YahooSportsConnector()
prospects = c.fetch_prospects()
print(f'{len(prospects)} prospects')
for p in prospects: print(f'  -> {p}')
"
```

**Result:** Returns 2 prospects â€” **both hardcoded fake data** ("Test Prospect 1", "Test Prospect 2").

**Root Causes:**

1. **Wrong CSS selectors:** Tries `div.player-card`, `div.player`, `article.player-card`, `tr.player-row`, etc. Yahoo Sports uses obfuscated Tailwind CSS class names (e.g., `_ys_1ejgpwy`, `_ys_u7h8d9`). No semantic class names exist.

2. **Hardcoded mock fallback in production path (lines ~300â€“315):** When no player elements are found, the `fetch_prospects()` method returns hardcoded mock data **directly in the production code path** â€” not in a test mock class. This means the scraper *always* silently returns fake data and appears to "work".

3. **Data IS available:** The Yahoo page returns 2.6 MB of server-rendered HTML containing real draft data (Cam Ward, Travis Hunter, Abdul Carter, etc.). The data is in the DOM but can only be extracted using the obfuscated CSS classes or by structural traversal (e.g., find text nodes matching player names, walk up to `<section>` containers).

**Mock Data That Should Be Removed:**
- Lines ~300â€“315 in `fetch_prospects()`: inline mock data return
- The `MockYahooSportsConnector` class at the bottom is fine (clearly labeled for testing)

---

### 7. NFL Draft Connector â€” `data_pipeline/sources/nfl_draft_connector.py`

**Test Command:**
```bash
poetry run python -c "
from data_pipeline.sources.nfl_draft_connector import NFLDraftConnector
c = NFLDraftConnector()
prospects = c.fetch_prospects()
print(f'{len(prospects)} prospects')
"
```

**Result:** Returns 10 prospects â€” **all hardcoded fake data** (Saquon Barkley II, Travis Hunter, Cam Ward, etc. â€” fabricated records with made-up grades).

**Root Causes:**

1. **Wrong API URL:** `_fetch_from_espn()` calls `https://site.api.espn.com/nfl/site/v2/draft` which returns **403 Forbidden**. This is not a valid ESPN API endpoint.

2. **Hardcoded `MOCK_PROSPECTS` (lines 15â€“25):** The class has 10 hardcoded fake prospects with invented data. After the ESPN API 403, `fetch_prospects()` falls back to this mock data and logs only a warning.

3. **Fake player data:** The mock data contains names that appear real but with fake stats (e.g., "Saquon Barkley II" â€” not a real prospect, "Jorrick Jones" â€” not a real player, grades are arbitrary).

4. **No real data source implemented:** Even the ESPN API parsing code (`_fetch_from_espn`) assumes a response format (`data["draft"]["players"]`) that was never verified against a real endpoint.

**Mock Data That Should Be Removed:**
- Lines 15â€“25: `MOCK_PROSPECTS` constant with 10 fake entries

---

## Cross-Cutting Issues

### 1. Mock Data in Production Code Paths
Three scrapers silently return fake data when they can't scrape real data, making failures invisible:

| Scraper | Mock Mechanism | Appears to Work? |
|---------|---------------|:----------------:|
| PFF Playwright | `_demo_with_mock_data()` in except handler | âœ… (silently fake) |
| Yahoo Sports | Inline mock return in `fetch_prospects()` | âœ… (silently fake) |
| NFL Draft Connector | `MOCK_PROSPECTS` fallback | âœ… (silently fake) |

**Recommendation:** Remove all mock/fake data from production code. Mock data should only exist in dedicated `Mock*` classes (like `MockESPNInjuryConnector` and `MockYahooSportsConnector` which are properly separated) or in test fixtures.

### 2. Every Scraper Uses Wrong CSS Selectors
All scrapers were written against *assumed* HTML structures rather than the *actual* DOM. Key corrections needed:

| Site | Scraper Expects | Actual Structure |
|------|----------------|-----------------|
| PFF | `div.card-prospects-box`, `span.school` | `div.g-card`, `div.g-label` + `div.g-data` |
| ESPN | `tr.injury-row`, `td.player-name` | `tr.Table__TR`, `td.col-name` |
| Yahoo | `div.player-card`, `h3.player-name` | `section._ys_*` (obfuscated Tailwind classes) |

### 3. Obsolete/Duplicate Scraper Files
There are 4 PFF scraper variants. Only `pff_scraper.py` (production) should remain:

| File | Status | Recommendation |
|------|--------|---------------|
| `pff_scraper.py` | Production (broken) | Fix selectors |
| `pff_scraper_playwright.py` | PoC with mock fallback | Remove or archive |
| `pff_scraper_poc.py` | Confirmed non-functional (requests only) | Remove |
| `pff_scraper_selenium.py` | Superseded by Playwright | Remove |

### 4. PFF Scraper Caches Empty Results
`pff_scraper.py` caches 0-prospect results. After one failed run, all subsequent cached runs return empty silently. The cache file currently contains:
```json
{"timestamp": 1770850470.7, "season": 2026, "page": 1, "prospects": [], "count": 0}
```
**Recommendation:** Never cache empty/zero results. Add a guard like `if len(prospects) > 0` before caching.

---

## What Real Data IS Available (verified)

| Source | URL | Data Available | Rendering |
|--------|-----|---------------|-----------|
| PFF Big Board | `pff.com/draft/big-board?season=2026` | 25 prospects per page (rank, name, position, class, school, height, weight, age, speed, snaps, grade) | JS-rendered, Playwright required, **data confirmed in captured HTML** |
| ESPN Injuries | `espn.com/nfl/injuries` (no trailing slash) | 32 team tables, 569 injury rows (name, position, return date, status, comment) | Server-rendered, `requests` works |
| Yahoo Draft Order | `sports.yahoo.com/nfl/draft/` | Full mock draft with player name, position, college, height, weight, class, age | Server-rendered, `requests` works, but uses obfuscated CSS classes |

---

## Priority Fix Order

1. **ğŸ”´ PFF Production Scraper** (`pff_scraper.py`) â€” Fix CSS selectors to match real DOM. Real data confirmed available in captured HTML. This is the primary data source.
2. **ğŸ”´ Remove mock data from production paths** â€” All 3 scrapers with inline mock fallbacks.
3. **ğŸŸ  ESPN Injury Scraper** â€” Fix URL (remove trailing slash) and update CSS selectors. Data is server-rendered and readily available.
4. **ğŸŸ¡ Yahoo Sports Scraper** â€” Challenging due to obfuscated CSS. May need structural/text-based parsing or an alternative approach.
5. **ğŸŸ¡ NFL Draft Connector** â€” Needs a valid API endpoint or should be replaced with a scraper approach.
6. **âšª Cleanup** â€” Remove `pff_scraper_poc.py`, `pff_scraper_selenium.py`, and `pff_scraper_playwright.py` (PoC).

---

## Appendix A: Complete PFF DOM Selector Map

**Source:** Captured live HTML (`page_1.html`, 1.4 MB, saved in project root as debug artifact by `pff_scraper.py` line ~285)

This file contains the real PFF page HTML with 25 prospect cards. It can be used as a test fixture.

### Card Container

```
div.g-card.g-card--border-gray
```

### Header Section (`div.m-ranking-header`)

| Field | Selector | Example Value |
|-------|----------|---------------|
| Rank | `div.m-ranking-header__rank-container` â†’ `div.m-rank__value` | `1` |
| Name | `div.m-ranking-header__main-details` â†’ `h3.m-ranking-header__title` â†’ `a` | `Fernando Mendoza` |
| Position | `div.m-ranking-header__details` â†’ `div.m-stat:nth-child(1)` â†’ `div.g-data` | `QB` |
| Class | `div.m-ranking-header__details` â†’ `div.m-stat:nth-child(2)` â†’ `div.g-data` | `RS Jr.` |

### Body Section (`div.g-card__content`)

Layout: `div.g-grid` with two columns:

**Left Column** (`div.g-span-12.g-span-6-lg.g-span-8-xl` â†’ `div.m-content-section` â†’ `div.m-stat-cluster`)

Each stat is a `div` child of the cluster containing:
```html
<div class="g-label g-mb-1">School</div>
<div class="g-data">
  <svg class="g-icon g-icon--team">...</svg>
  <span>Indiana</span>
</div>
```

| Field | Pattern | Example |
|-------|---------|---------|
| School | `div.g-label` text = "School" â†’ sibling `div.g-data` â†’ `span` | `Indiana` |
| Age | `div.g-label` text = "Age" â†’ sibling `div.g-data` | `â€”` (may be missing) |
| Height | `div.g-label` text = "Height" â†’ sibling `div.g-data` | `6' 5"` |
| Weight | `div.g-label` text = "Weight" â†’ sibling `div.g-data` | `225` |
| Speed | `div.g-label` text = "Speed" â†’ sibling `div.g-data` | `â€”` (may be missing) |

**Extraction strategy:** Iterate `div.m-stat-cluster > div` children. Each child contains a `div.g-label` and `div.g-data`. Use the label text to identify the field.

**Right Column** (`div.g-span-12.g-span-6-lg.g-span-4-xl` â†’ `table.g-table`)

Grade table with 3 columns:

| Column | Header `<th>` | Cell selector | Example |
|--------|--------------|---------------|---------|
| Season | `Season` | `td[data-cell-label="Season"]` | `2025` |
| Snaps | `Snaps` | `td[data-cell-label="Snaps"]` (class `u-text-right`) | `976` |
| Grade | `Season Grade` | `td[data-cell-label="Season Grade"]` â†’ `div.kyber-grade-badge` â†’ `div.kyber-grade-badge__info-text` | `91.6` |

**Grade badge structure:**
```html
<td data-cell-label="Season Grade">
  <div class="d-flex flex-row align-items-center justify-content-start">
    <div class="kyber-grade-badge">
      <div class="kyber-grade-badge__info">
        <div class="kyber-grade-badge__info-badge" style="background: rgb(2, 127, 164);"></div>
        <div class="kyber-grade-badge__info-bg" style="background: rgb(2, 127, 164);"></div>
        <div class="kyber-grade-badge__info-text">91.6</div>  <!-- â† GRADE VALUE -->
      </div>
    </div>
    <span class="g-ml-2 g-py-1 g-pill"><span>9<sup>th</sup> / 315</span> QB</span>
  </span>
</td>
```

**âš ï¸ Paywalled rows:** Only the most recent season row has visible snaps/grade. Older seasons show a lock icon (`button.pff-plus-badge` â†’ `svg.kyber-svg-lock-solid`). The scraper should only extract the first `<tbody> <tr>` data.

### Verified Prospect Data (first 3 from `page_1.html`)

| Rank | Name | Position | Class | School | Height | Weight | Snaps | Grade |
|------|------|----------|-------|--------|--------|--------|-------|-------|
| 1 | Fernando Mendoza | QB | RS Jr. | Indiana | 6' 5" | 225 | 976 | 91.6 |
| 2 | Rueben Bain Jr. | EDGE | â€” | â€” | â€” | â€” | â€” | â€” |
| 3 | Arvell Reese | LB | â€” | â€” | â€” | â€” | â€” | â€” |

---

## Appendix B: Complete ESPN Injury DOM Selector Map

**Source:** Live request to `https://www.espn.com/nfl/injuries` (no trailing slash), verified June 2025

### Page Structure

```
div.ResponsiveTable (Ã—32, one per team)
â”œâ”€â”€ div.Table__Title
â”‚   â””â”€â”€ div.flex.flex-row â†’ text = team name (e.g., "Arizona Cardinals")
â””â”€â”€ div.flex
    â””â”€â”€ div.Table__ScrollerWrapper
        â””â”€â”€ table.Table
            â”œâ”€â”€ thead
            â”‚   â””â”€â”€ tr â†’ th.Table__TH (Ã—5: NAME, POS, EST. RETURN DATE, STATUS, COMMENT)
            â””â”€â”€ tbody
                â””â”€â”€ tr.Table__TR.Table__TR--sm (Ã—N per team)
                    â”œâ”€â”€ td.col-name.Table__TD â†’ a[href] (player name + link)
                    â”œâ”€â”€ td.col-pos.Table__TD (position text)
                    â”œâ”€â”€ td.col-date.Table__TD (return date text)
                    â”œâ”€â”€ td.col-stat.Table__TD â†’ span.TextStatus (status text)
                    â””â”€â”€ td.col-desc.Table__TD (comment text)
```

### Team Name Extraction

The team name is **NOT** in each row â€” it's in a header **above** each team's table:

```python
wrapper = soup.find_all('div', class_='ResponsiveTable')  # 32 wrappers
for w in wrapper:
    team_name = w.find(class_='Table__Title').get_text(strip=True)
    rows = w.find_all('tr', class_='Table__TR')
    for row in rows:
        # Each row inherits team_name from its wrapper
```

### Status Classes (for color-coded status)

| Status | CSS Class | Example |
|--------|-----------|---------|
| Questionable | `TextStatus--yellow` | `<span class="TextStatus TextStatus--yellow">Questionable</span>` |
| Out | `TextStatus--red` | `<span class="TextStatus TextStatus--red">Out</span>` |
| Injured Reserve | `TextStatus--red` | `<span class="TextStatus TextStatus--red">Injured Reserve</span>` |

### Verified Data (first team)

**Arizona Cardinals** (25 rows):

| Name | POS | EST. RETURN DATE | STATUS |
|------|-----|------------------|--------|
| Jonah Williams | OT | Mar 1 | Questionable |
| Mack Wilson | â€” | â€” | â€” |

Total across all 32 teams: **569 injury rows** available.

---

## Appendix C: Complete Yahoo Sports DOM Selector Map

**Source:** Live request to `https://sports.yahoo.com/nfl/draft/`, verified June 2025

### Key Challenge: Obfuscated CSS Classes

Yahoo uses Tailwind-generated CSS class names (e.g., `_ys_1ejgpwy`, `_ys_u7h8d9`). These are **NOT stable** â€” they may change on any Yahoo deployment. A robust scraper must use **structural/text-based parsing**, not CSS class selectors.

### Page Structure

```
ul._ys_6oxte4 (prospect list â€” 257 items)
â””â”€â”€ li (one per prospect)
    â””â”€â”€ section._ys_1vv413w (prospect card)
        â”œâ”€â”€ div._ys_1ceho82 (header: pick + player info)
        â”‚   â””â”€â”€ div._ys_g5dbmv
        â”‚       â”œâ”€â”€ div._ys_18jhnv0 (pick info)
        â”‚       â”‚   â”œâ”€â”€ span._ys_1pbxhfo._ys_1dnwiv5 â†’ "RD1, PK2" (short form)
        â”‚       â”‚   â”œâ”€â”€ span._ys_1pbxhfo._ys_52mm7a â†’ "Round 1, Pick 2" (long form)
        â”‚       â”‚   â””â”€â”€ span._ys_zbzk5p â†’ "(from Browns)" (trade note, optional)
        â”‚       â”œâ”€â”€ img._ys_1bamtqw (player headshot)
        â”‚       â””â”€â”€ div._ys_u7h8d9 (name + position + school)
        â”‚           â”œâ”€â”€ div._ys_1ejgpwy â†’ "Travis Hunter" (player name)
        â”‚           â””â”€â”€ ul._ys_jprp27
        â”‚               â”œâ”€â”€ li._ys_jkbrcc â†’ "CB" (position)
        â”‚               â””â”€â”€ li._ys_jkbrcc â†’ "Colorado" (school)
        â””â”€â”€ div._ys_18pih1k (expandable detail section)
            â””â”€â”€ div._ys_1vv4mez
                â””â”€â”€ div (measurables + analysis)
                    â”œâ”€â”€ span._ys_1j0j0k â†’ "6' 1"" (value)
                    â”œâ”€â”€ span._ys_blfih4 â†’ "Height" (label)
                    â”œâ”€â”€ span._ys_1j0j0k â†’ "185" (value)
                    â”œâ”€â”€ span._ys_blfih4 â†’ "Weight" (label)
                    â”œâ”€â”€ span â†’ "JR" (class value, no consistent class)
                    â”œâ”€â”€ span._ys_blfih4 â†’ "Class" (label)
                    â”œâ”€â”€ span._ys_1j0j0k â†’ "21" (value)
                    â”œâ”€â”€ span._ys_blfih4 â†’ "Age" (label)
                    â”œâ”€â”€ h4._ys_uns4xu â†’ "Draft Grade: B+" (Yahoo's grade)
                    â”œâ”€â”€ span._ys_uns4xu â†’ "The Jaguars have made the first bold..." (analysis text)
                    â”œâ”€â”€ h4._ys_uns4xu â†’ "Player Comparisons"
                    â”œâ”€â”€ h4._ys_uns4xu â†’ "Attributes"
                    â””â”€â”€ div (Ã—N) â†’ "ğŸ’¨ Speed Demon", "ğŸ”§ Jack of all trades", etc.
```

### Recommended Extraction Strategy (CSS-class-independent)

Since Yahoo's classes are obfuscated and unstable, the scraper should use **structural navigation**:

```python
# 1. Find the prospect list  
prospect_list = soup.find('ul', recursive=True)  # Find the <ul> containing <li> with <section> children

# 2. For each prospect
for li in prospect_list.find_all('li', recursive=False):
    section = li.find('section')
    if not section:
        continue
    
    # 3. Extract from stripped_strings pattern
    texts = list(section.stripped_strings)
    # texts pattern: ["RD1, PK2", "Round 1, Pick 2", "(from Browns)", "Travis Hunter", "CB", "Colorado", ...]
    
    # 4. Or use structural position:
    #    - Player name: section's first div._ys_1ejgpwy (deepest div in header containing just name text)
    #    - Position + School: the <ul> inside the name's parent div â†’ <li> children (1st = position, 2nd = school)
    #    - Measurables: find all <span> pairs in detail section where label span has known text
```

### Verified Data (first 3 from live page)

| Pick | Name | Position | School | Height | Weight | Class | Age | Draft Grade |
|------|------|----------|--------|--------|--------|-------|-----|-------------|
| RD1, PK1 | Cam Ward | QB | Miami (FL) | 6' 2" | 223 | SR | 22 | â€” |
| RD1, PK2 | Travis Hunter | CB | Colorado | 6' 1" | 185 | JR | 21 | B+ |
| RD1, PK3 | Abdul Carter | EDGE | â€” | â€” | â€” | â€” | â€” | â€” |

Total prospects in list: **257**

---

## Appendix D: Unit Test Dependencies

**File:** `tests/unit/test_pff_scraper.py` (376 lines)

### Tests That Will Break When Selectors Are Fixed

The unit tests hardcode the **wrong** CSS selectors. When the production scraper is updated to use `div.g-card` instead of `div.card-prospects-box`, these tests must be updated simultaneously:

| Test | Line | Issue |
|------|------|-------|
| `test_parse_prospect_valid` | ~202 | Uses `<div class="card-prospects-box">` with `<h3>`, `<span class="school">`, etc. |
| `test_parse_prospect_missing_name` | ~222 | Same wrong structure |
| `test_parse_prospect_with_missing_fields` | ~237 | Same wrong structure |
| `test_parse_fixture_page1` | ~252 | Searches for `div.card-prospects-box` + expects fixture data with name "Patrick Surtain III" |
| `test_scraper_workflow` (integration) | ~345 | Same wrong selectors |

### Fixture Files Expected But Missing

The tests reference fixture files that don't exist:
- `tests/fixtures/pff/page_1.html` â€” **does not exist**
- `tests/fixtures/pff/page_2.html` â€” **does not exist**

**Recommendation:** Copy `page_1.html` (the debug artifact in project root, 1.4 MB of real PFF HTML) to `tests/fixtures/pff/page_1.html` and use it as the fixture. Update `test_parse_fixture_page1` to search for `div.g-card` and expect real prospect names (Fernando Mendoza, Rueben Bain Jr., etc.) instead of "Patrick Surtain III".

### Validator Tests (OK â€” No Changes Needed)

These tests are independent of CSS selectors and will continue to work:
- `TestGradeValidator` â€” validates grade value ranges
- `TestPositionValidator` â€” validates position codes
- `TestProspectValidator` â€” validates prospect dictionaries
- `TestProspectBatchValidator` â€” validates batch filtering
- `TestPFFProspectValidator` â€” validates embedded validator

---

## Appendix E: Debug Artifacts to Clean Up

| File | Size | Origin | Action |
|------|------|--------|--------|
| `page_1.html` (project root) | 1.4 MB | `pff_scraper.py` line ~285 debug dump | Move to `tests/fixtures/pff/page_1.html`, remove debug dump code |
| `data/cache/pff/season_2026_page_1.json` | ~100 B | Cached empty results | Delete (contains `"prospects": [], "count": 0`) |
| `debug_output.txt` (project root) | â€” | Debug artifact | Delete |
| `debug_yahoo.py` (project root) | â€” | Debug script | Delete or move to `examples/` |
